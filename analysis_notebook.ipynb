{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üçé Macronutrient Balancing Planner - Interactive Analysis\n",
        "\n",
        "This notebook provides comprehensive analysis and visualization of the RL-based meal planning system.\n",
        "\n",
        "## Features:\n",
        "- üìä **Interactive Training Progress** - Plotly-powered visualizations\n",
        "- üèÜ **Agent Performance Comparison** - RL vs Baselines\n",
        "- üçΩÔ∏è **AI Meal Planning Demo** - Live meal generation\n",
        "- üîç **Food Database Explorer** - Interactive data analysis\n",
        "- üéØ **User Profile Experimentation** - Real-time parameter testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        </script>\n",
              "        <script type=\"module\">import \"https://cdn.plot.ly/plotly-3.0.1.min\"</script>\n",
              "        "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ RL components loaded successfully!\n",
            "‚úÖ All imports completed!\n"
          ]
        }
      ],
      "source": [
        "# Core imports\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.offline as pyo\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Enable plotly in notebook\n",
        "pyo.init_notebook_mode(connected=True)\n",
        "\n",
        "# Import our modules\n",
        "from src.config import Config\n",
        "from src.data_loader import OpenFoodFactsAPI, RealFoodDatabase\n",
        "from src.user_profile import UserProfile\n",
        "from src.evaluation import EvaluationMetrics, BaselineComparison\n",
        "\n",
        "# Try to import RL components\n",
        "try:\n",
        "    from src.environment import MealPlanningEnvironment\n",
        "    from src.agent import PPOAgent\n",
        "    RL_AVAILABLE = True\n",
        "    print(\"‚úÖ RL components loaded successfully!\")\n",
        "except ImportError as e:\n",
        "    print(\"‚ö†Ô∏è  RL components not available. Run training first: python main.py --episodes 10\")\n",
        "    print(f\"Error: {e}\")\n",
        "    RL_AVAILABLE = False\n",
        "\n",
        "print(\"‚úÖ All imports completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Load Configuration & Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Configuration loaded\n",
            "üçï Food database loaded with 901 items\n",
            "üë§ User profile: 2682 cal/day\n",
            "‚úÖ All components loaded!\n"
          ]
        }
      ],
      "source": [
        "# Load configuration\n",
        "config = Config.from_yaml('config.yaml')\n",
        "config.viz_interactive = True  # Enable interactive plots\n",
        "print(f\"üìã Configuration loaded\")\n",
        "\n",
        "# Setup components\n",
        "api = OpenFoodFactsAPI(config)\n",
        "database = RealFoodDatabase(api, config)\n",
        "if len(database.foods) == 0:\n",
        "    print(\"üîÑ Populating food database (this may take a moment)...\")\n",
        "    database.populate_database()\n",
        "else:\n",
        "    print(f\"üçï Food database loaded with {len(database.foods)} items\")\n",
        "\n",
        "# Import enums for UserProfile\n",
        "from src.user_profile import Gender, ActivityLevel, Goal\n",
        "\n",
        "# Create user profile with correct parameters\n",
        "user_profile = UserProfile(\n",
        "    age=30, \n",
        "    gender=Gender.MALE, \n",
        "    weight=75.0, \n",
        "    height=180.0,\n",
        "    activity_level=ActivityLevel.MODERATELY_ACTIVE\n",
        ")\n",
        "\n",
        "# Set preferences after creation\n",
        "user_profile.preferences['liked_categories'] = ['chicken', 'rice', 'vegetables']\n",
        "user_profile.preferences['disliked_foods'] = ['liver']\n",
        "\n",
        "# Set weight goal if different from default\n",
        "user_profile.goals['weight_goal'] = Goal.MAINTAIN_WEIGHT\n",
        "\n",
        "# Recalculate target calories based on goals\n",
        "user_profile.goals['target_calories'] = user_profile.calculate_daily_calories()\n",
        "\n",
        "print(f\"üë§ User profile: {user_profile.goals['target_calories']} cal/day\")\n",
        "\n",
        "\n",
        "print(\"‚úÖ All components loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ Load Trained Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ‚Äç‚ôÇÔ∏è Environment created: (20,) obs, (2,) actions\n"
          ]
        },
        {
          "ename": "UnpicklingError",
          "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy._core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m model_path = \u001b[33m\"\u001b[39m\u001b[33mmodels/trained_agent.pth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(model_path):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     training_history = agent.training_history\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müéØ Loaded trained agent with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(training_history[\u001b[33m'\u001b[39m\u001b[33mepisode_rewards\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m episodes\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Documents\\RDS\\Y2S3\\ML\\Macronutrient-Balancing-Planner-using-RL\\src\\agent.py:409\u001b[39m, in \u001b[36mPPOAgent.load\u001b[39m\u001b[34m(self, filepath)\u001b[39m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, filepath: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    408\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load agent model\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     checkpoint = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m     \u001b[38;5;28mself\u001b[39m.actor.load_state_dict(checkpoint[\u001b[33m'\u001b[39m\u001b[33mactor_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    412\u001b[39m     \u001b[38;5;28mself\u001b[39m.critic.load_state_dict(checkpoint[\u001b[33m'\u001b[39m\u001b[33mcritic_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Documents\\RDS\\Y2S3\\ML\\Macronutrient-Balancing-Planner-using-RL\\.venv\\Lib\\site-packages\\torch\\serialization.py:1524\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1516\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1517\u001b[39m                     opened_zipfile,\n\u001b[32m   1518\u001b[39m                     map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1521\u001b[39m                     **pickle_load_args,\n\u001b[32m   1522\u001b[39m                 )\n\u001b[32m   1523\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1525\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1526\u001b[39m             opened_zipfile,\n\u001b[32m   1527\u001b[39m             map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1530\u001b[39m             **pickle_load_args,\n\u001b[32m   1531\u001b[39m         )\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
            "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy._core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
          ]
        }
      ],
      "source": [
        "if RL_AVAILABLE:\n",
        "    # Create environment\n",
        "    env = MealPlanningEnvironment(database, user_profile, config)\n",
        "    print(f\"üèÉ‚Äç‚ôÇÔ∏è Environment created: {env.observation_space.shape} obs, {env.action_space.shape} actions\")\n",
        "    \n",
        "    # Create and load agent\n",
        "    obs_dim = env.observation_space.shape[0]\n",
        "    action_dim = env.action_space.shape[0]\n",
        "    agent = PPOAgent(obs_dim, action_dim, config)\n",
        "    \n",
        "    # Load trained model\n",
        "    model_path = \"models/trained_agent.pth\"\n",
        "    if os.path.exists(model_path):\n",
        "        agent.load(model_path)\n",
        "        training_history = agent.training_history\n",
        "        print(f\"üéØ Loaded trained agent with {len(training_history['episode_rewards'])} episodes\")\n",
        "    else:\n",
        "        print(f\"‚ùå No trained model found. Run: python main.py --episodes 20\")\n",
        "        training_history = None\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Cannot load agent - RL components not available\")\n",
        "    training_history = None\n",
        "    env = None\n",
        "    agent = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Interactive Training Progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'training_history' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtraining_history\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(training_history[\u001b[33m'\u001b[39m\u001b[33mepisode_rewards\u001b[39m\u001b[33m'\u001b[39m]) > \u001b[32m0\u001b[39m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Create interactive training progress plot\u001b[39;00m\n\u001b[32m      3\u001b[39m     rewards = training_history[\u001b[33m'\u001b[39m\u001b[33mepisode_rewards\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m     episodes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rewards)))\n",
            "\u001b[31mNameError\u001b[39m: name 'training_history' is not defined"
          ]
        }
      ],
      "source": [
        "if training_history and len(training_history['episode_rewards']) > 0:\n",
        "    # Create interactive training progress plot\n",
        "    rewards = training_history['episode_rewards']\n",
        "    episodes = list(range(len(rewards)))\n",
        "    \n",
        "    # Moving average for smoothing\n",
        "    window = min(10, len(rewards) // 3)\n",
        "    if window > 1:\n",
        "        moving_avg = pd.Series(rewards).rolling(window=window).mean()\n",
        "    else:\n",
        "        moving_avg = rewards\n",
        "    \n",
        "    fig = go.Figure()\n",
        "    \n",
        "    # Raw rewards\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=episodes, y=rewards,\n",
        "        mode='lines+markers',\n",
        "        name='Episode Rewards',\n",
        "        line=dict(color='lightblue', width=1),\n",
        "        marker=dict(size=4),\n",
        "        hovertemplate='Episode: %{x}<br>Reward: %{y:.3f}<extra></extra>'\n",
        "    ))\n",
        "    \n",
        "    # Moving average\n",
        "    if window > 1:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=episodes, y=moving_avg,\n",
        "            mode='lines',\n",
        "            name=f'Moving Average ({window})',\n",
        "            line=dict(color='red', width=3)\n",
        "        ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title='üöÄ Training Progress - Interactive View',\n",
        "        xaxis_title='Episode',\n",
        "        yaxis_title='Reward',\n",
        "        hovermode='x unified',\n",
        "        height=500,\n",
        "        template='plotly_white'\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    # Training statistics\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üìä TRAINING STATISTICS\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Total Episodes: {len(rewards)}\")\n",
        "    print(f\"Final Reward: {rewards[-1]:.3f}\")\n",
        "    print(f\"Best Reward: {max(rewards):.3f}\")\n",
        "    print(f\"Average Reward: {np.mean(rewards):.3f}\")\n",
        "    print(f\"Improvement: {((rewards[-1] - rewards[0]) / abs(rewards[0]) * 100 if rewards[0] != 0 else 0):.1f}%\")\n",
        "else:\n",
        "    print(\"‚ùå No training history available. Run training first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèÜ Agent Performance Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if RL_AVAILABLE and training_history and agent:\n",
        "    print(\"üîÑ Running agent evaluation and baseline comparison...\")\n",
        "    \n",
        "    # Initialize evaluation components\n",
        "    evaluator = EvaluationMetrics(config)\n",
        "    baseline_comparison = BaselineComparison(config)\n",
        "    \n",
        "    # Evaluate trained agent\n",
        "    print(\"Evaluating RL agent...\")\n",
        "    rl_results = evaluator.evaluate_agent(agent, env, num_episodes=10)\n",
        "    \n",
        "    # Run baseline comparisons\n",
        "    print(\"Running baseline comparisons...\")\n",
        "    baseline_results = baseline_comparison.run_comparison(env, num_episodes=5)\n",
        "    \n",
        "    # Combine results\n",
        "    all_results = {\n",
        "        'RL Agent': rl_results,\n",
        "        **baseline_results\n",
        "    }\n",
        "    \n",
        "    # Create interactive comparison plot\n",
        "    agents = list(all_results.keys())\n",
        "    avg_rewards = [result.get_average_reward() for result in all_results.values()]\n",
        "    success_rates = [result.get_success_rate() for result in all_results.values()]\n",
        "    \n",
        "    # Create comparison plot\n",
        "    fig = make_subplots(\n",
        "        rows=1, cols=2,\n",
        "        subplot_titles=('Average Reward Comparison', 'Success Rate Comparison'),\n",
        "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
        "    )\n",
        "    \n",
        "    # Reward comparison\n",
        "    colors = ['green' if agent == 'RL Agent' else 'lightcoral' for agent in agents]\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=agents, y=avg_rewards, name='Avg Reward', \n",
        "               marker_color=colors, text=[f'{r:.2f}' for r in avg_rewards],\n",
        "               textposition='auto'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # Success rate comparison\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=agents, y=[r*100 for r in success_rates], name='Success Rate (%)',\n",
        "               marker_color=colors, text=[f'{r:.1%}' for r in success_rates],\n",
        "               textposition='auto'),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title='üèÜ Agent Performance Comparison',\n",
        "        height=500,\n",
        "        showlegend=False,\n",
        "        template='plotly_white'\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    # Print detailed results\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üèÜ DETAILED COMPARISON RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for i, (name, result) in enumerate(all_results.items(), 1):\n",
        "        avg_reward = result.get_average_reward()\n",
        "        success_rate = result.get_success_rate()\n",
        "        print(f\"{i}. {name:12}: Reward = {avg_reward:8.3f}, Success = {success_rate:.1%}\")\n",
        "        \n",
        "else:\n",
        "    print(\"‚ùå Cannot run comparison - Agent not available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üçΩÔ∏è Interactive Meal Planning Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üçΩÔ∏è Generating AI meal plan...\n",
            "\n",
            "======================================================================\n",
            "üçΩÔ∏è AI-GENERATED MEAL PLAN\n",
            "======================================================================\n",
            "\n",
            "üç¥ Meal 1: Quinoa poulet et s√©same\n",
            "   Portion: 123g\n",
            "   Calories: 215 kcal\n",
            "   P: 8.5g | C: 22.1g | F: 8.5g\n",
            "   Reward Score: 0.218\n",
            "\n",
            "üç¥ Meal 2: Quinoa poulet et s√©same\n",
            "   Portion: 123g\n",
            "   Calories: 215 kcal\n",
            "   P: 8.5g | C: 22.1g | F: 8.5g\n",
            "   Reward Score: 0.182\n",
            "\n",
            "üç¥ Meal 3: DUO DE QUINOA AUX LEGUMES\n",
            "   Portion: 123g\n",
            "   Calories: 178 kcal\n",
            "   P: 5.9g | C: 27.0g | F: 3.9g\n",
            "   Reward Score: 0.422\n",
            "\n",
            "üç¥ Meal 4: DUO DE QUINOA AUX LEGUMES\n",
            "   Portion: 123g\n",
            "   Calories: 178 kcal\n",
            "   P: 5.9g | C: 27.0g | F: 3.9g\n",
            "   Reward Score: 0.511\n",
            "\n",
            "üç¥ Meal 5: Tilda Steamed Brown Basmati and Quinoa\n",
            "   Portion: 123g\n",
            "   Calories: 162 kcal\n",
            "   P: 3.5g | C: 29.4g | F: 2.5g\n",
            "   Reward Score: 0.701\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 107\u001b[39m\n\u001b[32m     92\u001b[39m     fig.add_trace(\n\u001b[32m     93\u001b[39m         go.Bar(x=df_meals[\u001b[33m'\u001b[39m\u001b[33mmeal\u001b[39m\u001b[33m'\u001b[39m], y=df_meals[\u001b[33m'\u001b[39m\u001b[33mreward\u001b[39m\u001b[33m'\u001b[39m], \n\u001b[32m     94\u001b[39m                name=\u001b[33m'\u001b[39m\u001b[33mReward\u001b[39m\u001b[33m'\u001b[39m, marker_color=\u001b[33m'\u001b[39m\u001b[33mgreen\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     97\u001b[39m         row=\u001b[32m2\u001b[39m, col=\u001b[32m2\u001b[39m\n\u001b[32m     98\u001b[39m     )\n\u001b[32m    100\u001b[39m     fig.update_layout(\n\u001b[32m    101\u001b[39m         title=\u001b[33m'\u001b[39m\u001b[33müçΩÔ∏è Meal Plan Analysis Dashboard\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    102\u001b[39m         height=\u001b[32m700\u001b[39m,\n\u001b[32m    103\u001b[39m         showlegend=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    104\u001b[39m         template=\u001b[33m'\u001b[39m\u001b[33mplotly_white\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    105\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Show targets vs actual\u001b[39;00m\n\u001b[32m    110\u001b[39m target_cals = user_profile.goals[\u001b[33m'\u001b[39m\u001b[33mtarget_calories\u001b[39m\u001b[33m'\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Documents\\RDS\\Y2S3\\ML\\Macronutrient-Balancing-Planner-using-RL\\.venv\\Lib\\site-packages\\plotly\\basedatatypes.py:3420\u001b[39m, in \u001b[36mBaseFigure.show\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3387\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3388\u001b[39m \u001b[33;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[32m   3389\u001b[39m \u001b[33;03mspecified by the renderer argument\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3416\u001b[39m \u001b[33;03mNone\u001b[39;00m\n\u001b[32m   3417\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3418\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpio\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3420\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Documents\\RDS\\Y2S3\\ML\\Macronutrient-Balancing-Planner-using-RL\\.venv\\Lib\\site-packages\\plotly\\io\\_renderers.py:415\u001b[39m, in \u001b[36mshow\u001b[39m\u001b[34m(fig, renderer, validate, **kwargs)\u001b[39m\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    411\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m     )\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat.__version__) < Version(\u001b[33m\"\u001b[39m\u001b[33m4.2.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    416\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    417\u001b[39m     )\n\u001b[32m    419\u001b[39m display_jupyter_version_warnings()\n\u001b[32m    421\u001b[39m ipython_display.display(bundle, raw=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[31mValueError\u001b[39m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
          ]
        }
      ],
      "source": [
        "if RL_AVAILABLE and agent:\n",
        "    print(\"üçΩÔ∏è Generating AI meal plan...\")\n",
        "    \n",
        "    # Reset environment and generate meal plan\n",
        "    observation, _ = env.reset()\n",
        "    meals_data = []\n",
        "    total_nutrition = {'calories': 0, 'protein': 0, 'carbohydrates': 0, 'fat': 0}\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üçΩÔ∏è AI-GENERATED MEAL PLAN\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    for step in range(5):  # Generate 5 meals\n",
        "        # Get action from trained agent\n",
        "        action, _, _ = agent.select_action(observation, training=False)\n",
        "        \n",
        "        # Take step in environment\n",
        "        observation, reward, done, truncated, info = env.step(action)\n",
        "        \n",
        "        if 'selected_food' in info:\n",
        "            food = info['selected_food']\n",
        "            portion = info['portion_size']\n",
        "            meal_nutrition = info['meal_nutrition']\n",
        "            \n",
        "            # Store meal data for visualization\n",
        "            meals_data.append({\n",
        "                'meal': f'Meal {step + 1}',\n",
        "                'food': food.name,\n",
        "                'portion': portion,\n",
        "                'calories': meal_nutrition['calories'],\n",
        "                'protein': meal_nutrition['protein'],\n",
        "                'carbohydrates': meal_nutrition['carbohydrates'],\n",
        "                'fat': meal_nutrition['fat'],\n",
        "                'reward': reward\n",
        "            })\n",
        "            \n",
        "            print(f\"\\nüç¥ Meal {step + 1}: {food.name}\")\n",
        "            print(f\"   Portion: {portion:.0f}g\")\n",
        "            print(f\"   Calories: {meal_nutrition['calories']:.0f} kcal\")\n",
        "            print(f\"   P: {meal_nutrition['protein']:.1f}g | C: {meal_nutrition['carbohydrates']:.1f}g | F: {meal_nutrition['fat']:.1f}g\")\n",
        "            print(f\"   Reward Score: {reward:.3f}\")\n",
        "            \n",
        "            # Update totals\n",
        "            for key in total_nutrition:\n",
        "                total_nutrition[key] += meal_nutrition[key]\n",
        "        \n",
        "        if done or truncated:\n",
        "            break\n",
        "    \n",
        "    # Create interactive meal visualization\n",
        "    if meals_data:\n",
        "        df_meals = pd.DataFrame(meals_data)\n",
        "        \n",
        "        # Nutritional breakdown chart\n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            subplot_titles=('Calories per Meal', 'Protein Distribution', \n",
        "                           'Macronutrient Breakdown', 'Reward Scores'),\n",
        "            specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
        "                   [{\"type\": \"pie\"}, {\"type\": \"bar\"}]]\n",
        "        )\n",
        "        \n",
        "        # Calories per meal\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=df_meals['meal'], y=df_meals['calories'], \n",
        "                   name='Calories', marker_color='orange',\n",
        "                   text=[f\"{cal:.0f}\" for cal in df_meals['calories']],\n",
        "                   textposition='auto'),\n",
        "            row=1, col=1\n",
        "        )\n",
        "        \n",
        "        # Protein distribution\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=df_meals['meal'], y=df_meals['protein'], \n",
        "                   name='Protein', marker_color='red',\n",
        "                   text=[f\"{prot:.1f}g\" for prot in df_meals['protein']],\n",
        "                   textposition='auto'),\n",
        "            row=1, col=2\n",
        "        )\n",
        "        \n",
        "        # Macronutrient pie chart\n",
        "        fig.add_trace(\n",
        "            go.Pie(labels=['Protein', 'Carbohydrates', 'Fat'],\n",
        "                   values=[total_nutrition['protein']*4, \n",
        "                          total_nutrition['carbohydrates']*4, \n",
        "                          total_nutrition['fat']*9],\n",
        "                   name='Macros'),\n",
        "            row=2, col=1\n",
        "        )\n",
        "        \n",
        "        # Reward scores\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=df_meals['meal'], y=df_meals['reward'], \n",
        "                   name='Reward', marker_color='green',\n",
        "                   text=[f\"{rew:.2f}\" for rew in df_meals['reward']],\n",
        "                   textposition='auto'),\n",
        "            row=2, col=2\n",
        "        )\n",
        "        \n",
        "        fig.update_layout(\n",
        "            title='üçΩÔ∏è Meal Plan Analysis Dashboard',\n",
        "            height=700,\n",
        "            showlegend=False,\n",
        "            template='plotly_white'\n",
        "        )\n",
        "        \n",
        "        fig.show()\n",
        "    \n",
        "    # Show targets vs actual\n",
        "    target_cals = user_profile.goals['target_calories']\n",
        "    target_protein, target_carbs, target_fat = user_profile.goals['macro_grams']\n",
        "    \n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    print(\"üìä DAILY NUTRITION SUMMARY\")\n",
        "    print(\"-\"*70)\n",
        "    print(f\"Calories: {total_nutrition['calories']:.0f} / {target_cals} ({total_nutrition['calories']/target_cals:.1%})\")\n",
        "    print(f\"Protein:  {total_nutrition['protein']:.1f}g / {target_protein:.1f}g ({total_nutrition['protein']/target_protein:.1%})\")\n",
        "    print(f\"Carbs:    {total_nutrition['carbohydrates']:.1f}g / {target_carbs:.1f}g ({total_nutrition['carbohydrates']/target_carbs:.1%})\")\n",
        "    print(f\"Fat:      {total_nutrition['fat']:.1f}g / {target_fat:.1f}g ({total_nutrition['fat']/target_fat:.1%})\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Cannot generate meal plan - Agent not available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Food Database Explorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Exploring food database with 901 items...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     21\u001b[39m fig = px.scatter(\n\u001b[32m     22\u001b[39m     df_foods, \n\u001b[32m     23\u001b[39m     x=\u001b[33m'\u001b[39m\u001b[33mcalories\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     template=\u001b[33m'\u001b[39m\u001b[33mplotly_white\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     31\u001b[39m )\n\u001b[32m     33\u001b[39m fig.update_layout(height=\u001b[32m600\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Food statistics\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Documents\\RDS\\Y2S3\\ML\\Macronutrient-Balancing-Planner-using-RL\\.venv\\Lib\\site-packages\\plotly\\basedatatypes.py:3420\u001b[39m, in \u001b[36mBaseFigure.show\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3387\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3388\u001b[39m \u001b[33;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[32m   3389\u001b[39m \u001b[33;03mspecified by the renderer argument\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3416\u001b[39m \u001b[33;03mNone\u001b[39;00m\n\u001b[32m   3417\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3418\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpio\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3420\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Documents\\RDS\\Y2S3\\ML\\Macronutrient-Balancing-Planner-using-RL\\.venv\\Lib\\site-packages\\plotly\\io\\_renderers.py:415\u001b[39m, in \u001b[36mshow\u001b[39m\u001b[34m(fig, renderer, validate, **kwargs)\u001b[39m\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    411\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m     )\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat.__version__) < Version(\u001b[33m\"\u001b[39m\u001b[33m4.2.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    416\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    417\u001b[39m     )\n\u001b[32m    419\u001b[39m display_jupyter_version_warnings()\n\u001b[32m    421\u001b[39m ipython_display.display(bundle, raw=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[31mValueError\u001b[39m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
          ]
        }
      ],
      "source": [
        "# Interactive food database exploration\n",
        "print(f\"üîç Exploring food database with {len(database.foods)} items...\")\n",
        "\n",
        "# Sample foods for analysis\n",
        "sample_foods = list(database.foods.values())[:200]  # First 200 foods\n",
        "foods_data = []\n",
        "\n",
        "for food in sample_foods:\n",
        "    foods_data.append({\n",
        "        'name': food.name[:30],  # Truncate long names\n",
        "        'calories': food.nutrition.calories,\n",
        "        'protein': food.nutrition.protein,\n",
        "        'carbohydrates': food.nutrition.carbohydrates,\n",
        "        'fat': food.nutrition.fat,\n",
        "        'quality_score': food.quality_score\n",
        "    })\n",
        "\n",
        "df_foods = pd.DataFrame(foods_data)\n",
        "\n",
        "# Create interactive scatter plot\n",
        "fig = px.scatter(\n",
        "    df_foods, \n",
        "    x='calories', \n",
        "    y='protein',\n",
        "    size='quality_score',\n",
        "    color='fat',\n",
        "    hover_data=['name', 'carbohydrates'],\n",
        "    title='üçï Food Database: Calories vs Protein (Size=Quality, Color=Fat)',\n",
        "    labels={'calories': 'Calories (per 100g)', 'protein': 'Protein (g)'},\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "fig.update_layout(height=600)\n",
        "fig.show()\n",
        "\n",
        "# Food statistics\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üìä FOOD DATABASE STATISTICS\")\n",
        "print(\"=\"*50)\n",
        "print(df_foods.describe().round(2))\n",
        "\n",
        "# Top foods by category\n",
        "print(\"\\nüèÜ TOP FOODS BY PROTEIN:\")\n",
        "top_protein = df_foods.nlargest(5, 'protein')[['name', 'protein', 'calories']]\n",
        "for idx, row in top_protein.iterrows():\n",
        "    print(f\"  {row['name']}: {row['protein']:.1f}g protein, {row['calories']:.0f} kcal\")\n",
        "\n",
        "print(\"\\nüåü TOP FOODS BY QUALITY:\")\n",
        "top_quality = df_foods.nlargest(5, 'quality_score')[['name', 'quality_score', 'calories']]\n",
        "for idx, row in top_quality.iterrows():\n",
        "    print(f\"  {row['name']}: Quality {row['quality_score']:.2f}, {row['calories']:.0f} kcal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Interactive User Profile Experimentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive experimentation with different user profiles\n",
        "try:\n",
        "    from ipywidgets import interact, IntSlider, FloatSlider, Dropdown\n",
        "    \n",
        "    def experiment_user_profile(age=30, weight=75, height=180, activity='MODERATELY_ACTIVE'):\n",
        "        \"\"\"Interactive user profile experimentation\"\"\"\n",
        "        test_profile = UserProfile(\n",
        "            age=age, gender='male', weight=weight, height=height,\n",
        "            activity_level=activity, weight_goal='maintain'\n",
        "        )\n",
        "        \n",
        "        print(f\"\\nüë§ Profile Analysis:\")\n",
        "        print(f\"BMI: {test_profile.personal_info['bmi']:.1f} ({test_profile.personal_info['bmi_category']})\")\n",
        "        print(f\"BMR: {test_profile.goals['bmr']:.0f} kcal/day\")\n",
        "        print(f\"Target Calories: {test_profile.goals['target_calories']:.0f} kcal/day\")\n",
        "        print(f\"Protein: {test_profile.goals['macro_grams'][0]:.1f}g ({test_profile.goals['macro_ratios'][0]:.0%})\")\n",
        "        print(f\"Carbs: {test_profile.goals['macro_grams'][1]:.1f}g ({test_profile.goals['macro_ratios'][1]:.0%})\")\n",
        "        print(f\"Fat: {test_profile.goals['macro_grams'][2]:.1f}g ({test_profile.goals['macro_ratios'][2]:.0%})\")\n",
        "        \n",
        "        # Create quick visualization\n",
        "        macros = test_profile.goals['macro_grams']\n",
        "        fig = go.Figure(data=[\n",
        "            go.Pie(labels=['Protein', 'Carbohydrates', 'Fat'],\n",
        "                   values=[macros[0]*4, macros[1]*4, macros[2]*9],\n",
        "                   hole=0.3)\n",
        "        ])\n",
        "        fig.update_layout(\n",
        "            title=f\"Calorie Distribution - {test_profile.goals['target_calories']:.0f} kcal/day\",\n",
        "            template='plotly_white'\n",
        "        )\n",
        "        fig.show()\n",
        "    \n",
        "    # Create interactive widgets\n",
        "    print(\"üéõÔ∏è Interactive User Profile Experimentation:\")\n",
        "    print(\"Use the sliders below to see how different parameters affect nutritional needs:\\n\")\n",
        "    \n",
        "    interact(\n",
        "        experiment_user_profile,\n",
        "        age=IntSlider(min=18, max=80, step=1, value=30, description='Age:'),\n",
        "        weight=FloatSlider(min=40, max=150, step=5, value=75, description='Weight (kg):'),\n",
        "        height=IntSlider(min=140, max=220, step=5, value=180, description='Height (cm):'),\n",
        "        activity=Dropdown(\n",
        "            options=['SEDENTARY', 'LIGHTLY_ACTIVE', 'MODERATELY_ACTIVE', 'VERY_ACTIVE', 'EXTREMELY_ACTIVE'],\n",
        "            value='MODERATELY_ACTIVE',\n",
        "            description='Activity Level:'\n",
        "        )\n",
        "    )\n",
        "    \n",
        "except ImportError:\n",
        "    print(\"üí° Install ipywidgets for interactive controls: pip install ipywidgets\")\n",
        "    print(\"\\nShowing sample profile comparisons instead:\")\n",
        "    \n",
        "    # Show sample comparisons\n",
        "    sample_profiles = [\n",
        "        {'name': 'Young Active', 'age': 25, 'weight': 60, 'height': 165, 'activity': 'VERY_ACTIVE'},\n",
        "        {'name': 'Middle-aged', 'age': 40, 'weight': 80, 'height': 175, 'activity': 'MODERATELY_ACTIVE'},\n",
        "        {'name': 'Senior', 'age': 65, 'weight': 70, 'height': 170, 'activity': 'LIGHTLY_ACTIVE'}\n",
        "    ]\n",
        "    \n",
        "    comparison_data = []\n",
        "    for profile_info in sample_profiles:\n",
        "        profile = UserProfile(\n",
        "            age=profile_info['age'], gender='male', \n",
        "            weight=profile_info['weight'], height=profile_info['height'],\n",
        "            activity_level=profile_info['activity'], weight_goal='maintain'\n",
        "        )\n",
        "        comparison_data.append({\n",
        "            'Profile': profile_info['name'],\n",
        "            'Calories': profile.goals['target_calories'],\n",
        "            'Protein': profile.goals['macro_grams'][0],\n",
        "            'Carbs': profile.goals['macro_grams'][1],\n",
        "            'Fat': profile.goals['macro_grams'][2]\n",
        "        })\n",
        "    \n",
        "    df_comparison = pd.DataFrame(comparison_data)\n",
        "    \n",
        "    # Create comparison chart\n",
        "    fig = go.Figure()\n",
        "    \n",
        "    fig.add_trace(go.Bar(\n",
        "        name='Calories', \n",
        "        x=df_comparison['Profile'], \n",
        "        y=df_comparison['Calories'],\n",
        "        marker_color='skyblue',\n",
        "        text=[f\"{cal:.0f}\" for cal in df_comparison['Calories']],\n",
        "        textposition='auto'\n",
        "    ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title='üìä Sample Profile Comparison - Daily Calorie Needs',\n",
        "        yaxis_title='Calories',\n",
        "        height=400,\n",
        "        template='plotly_white'\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    print(\"\\nüìã Sample Profile Comparison:\")\n",
        "    print(df_comparison.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Quick Training Session (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick training session in notebook\n",
        "# WARNING: This will train a new agent from scratch!\n",
        "\n",
        "ENABLE_QUICK_TRAINING = False  # Change to True to enable\n",
        "\n",
        "if ENABLE_QUICK_TRAINING and RL_AVAILABLE:\n",
        "    print(\"üöÄ Starting quick training session...\")\n",
        "    print(\"‚ö†Ô∏è  This will create a new agent and train from scratch!\")\n",
        "    \n",
        "    # Create fresh agent\n",
        "    quick_agent = PPOAgent(obs_dim, action_dim, config)\n",
        "    \n",
        "    # Train for a few episodes with real-time plotting\n",
        "    training_episodes = 30\n",
        "    print(f\"Training for {training_episodes} episodes...\")\n",
        "    \n",
        "    quick_history = quick_agent.train(\n",
        "        environment=env, \n",
        "        num_episodes=training_episodes, \n",
        "        update_frequency=5\n",
        "    )\n",
        "    \n",
        "    # Plot live results\n",
        "    rewards = quick_history['episode_rewards']\n",
        "    episodes = list(range(len(rewards)))\n",
        "    \n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=episodes, y=rewards,\n",
        "        mode='lines+markers',\n",
        "        name='Training Rewards',\n",
        "        line=dict(color='blue', width=2),\n",
        "        marker=dict(size=4)\n",
        "    ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title=f'üèÉ‚Äç‚ôÇÔ∏è Quick Training Results ({training_episodes} episodes)',\n",
        "        xaxis_title='Episode',\n",
        "        yaxis_title='Reward',\n",
        "        height=400,\n",
        "        template='plotly_white'\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    print(f\"‚úÖ Quick training completed!\")\n",
        "    print(f\"Initial reward: {rewards[0]:.3f}\")\n",
        "    print(f\"Final reward: {rewards[-1]:.3f}\")\n",
        "    print(f\"Improvement: {((rewards[-1] - rewards[0]) / abs(rewards[0]) * 100 if rewards[0] != 0 else 0):.1f}%\")\n",
        "    \n",
        "else:\n",
        "    print(\"üí° Set ENABLE_QUICK_TRAINING = True to run a quick training session\")\n",
        "    print(\"   (This will create and train a new agent from scratch)\")\n",
        "    \n",
        "    if not RL_AVAILABLE:\n",
        "        print(\"‚ùå RL components not available - cannot train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Summary & Next Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"üìã INTERACTIVE ANALYSIS SESSION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if RL_AVAILABLE and training_history:\n",
        "    print(f\"‚úÖ Successfully analyzed trained RL agent\")\n",
        "    print(f\"üìä Processed {len(training_history['episode_rewards'])} training episodes\")\n",
        "    if training_history['episode_rewards']:\n",
        "        print(f\"üèÜ Final performance: {training_history['episode_rewards'][-1]:.3f} reward\")\n",
        "    print(f\"üçΩÔ∏è Generated AI meal plan with interactive visualizations\")\n",
        "    print(f\"üèÜ Compared against baseline agents\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No trained agent available for analysis\")\n",
        "    print(\"üí° Run training first: python main.py --episodes 20 --verbose\")\n",
        "\n",
        "print(f\"\\nüçï Food database: {len(database.foods)} items analyzed\")\n",
        "print(f\"üë§ User profile: {user_profile.goals['target_calories']} cal/day target\")\n",
        "print(f\"üìä Generated multiple interactive visualizations\")\n",
        "\n",
        "print(\"\\nüî¨ EXPERIMENT IDEAS:\")\n",
        "print(\"‚Ä¢ Modify user profile parameters and re-run meal generation\")\n",
        "print(\"‚Ä¢ Change reward weights in config.yaml and retrain\")\n",
        "print(\"‚Ä¢ Explore different foods by adjusting database filters\")\n",
        "print(\"‚Ä¢ Run longer training sessions for better convergence\")\n",
        "print(\"‚Ä¢ Compare performance across different user demographics\")\n",
        "print(\"‚Ä¢ Experiment with different dietary restrictions\")\n",
        "\n",
        "print(\"\\nüíª ADVANCED EXPERIMENTS:\")\n",
        "print(\"‚Ä¢ Edit src/environment.py to modify reward functions\")\n",
        "print(\"‚Ä¢ Add new baseline strategies in src/evaluation.py\")\n",
        "print(\"‚Ä¢ Create custom user profiles with specific dietary needs\")\n",
        "print(\"‚Ä¢ Implement multi-day meal planning scenarios\")\n",
        "\n",
        "print(\"\\n‚ú® This notebook provides a complete interactive research environment!\")\n",
        "print(\"   All visualizations are interactive - hover, zoom, and explore the data.\")\n",
        "print(\"   Feel free to modify any cells and experiment with parameters.\")\n",
        "\n",
        "# Show available files and directories\n",
        "print(\"\\nüìÅ Generated Files:\")\n",
        "if Path('models').exists():\n",
        "    models = list(Path('models').glob('*.pth'))\n",
        "    print(f\"   Models: {len(models)} saved agent(s)\")\n",
        "    \n",
        "if Path('plots').exists():\n",
        "    plots = list(Path('plots').glob('*.html'))\n",
        "    print(f\"   Plots: {len(plots)} HTML dashboard(s)\")\n",
        "    \n",
        "if Path('cache').exists():\n",
        "    cache_files = list(Path('cache').glob('*'))\n",
        "    print(f\"   Cache: {len(cache_files)} cached file(s)\")\n",
        "\n",
        "print(\"\\nüéØ Happy experimenting with your RL-powered meal planner!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
